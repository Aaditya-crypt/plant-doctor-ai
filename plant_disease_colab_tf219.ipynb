{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469b4a3d",
   "metadata": {},
   "source": [
    "# Plant Disease Detection — Colab Training Notebook (TF 2.19 compatible)\n",
    "**Instructions**\n",
    "1. Mount Google Drive (cell below) and upload `archive.zip` to your Drive root or adjust paths.\n",
    "2. Run cells top-to-bottom. Use GPU runtime (Runtime → Change runtime type → GPU).\n",
    "3. This notebook trains a 16-class classifier, saves `plant_disease_model.keras` (Keras native format),\n",
    "   and writes `class_indices.json` for frontend mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62568699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust zip_path if your archive is stored in a different Drive folder\n",
    "import zipfile, os, shutil\n",
    "zip_path = \"/content/drive/MyDrive/archive.zip\"  # change if needed\n",
    "extract_path = \"/content/plant_dataset\"\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_path)\n",
    "    print(\"✅ Extracted to:\", extract_path)\n",
    "else:\n",
    "    print(\"Dataset folder already exists:\", extract_path)\n",
    "\n",
    "# Quick check - print top folders (class folders)\n",
    "print('Top-level folders in dataset:')\n",
    "print(sorted(os.listdir(extract_path))[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0858cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e911bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "DATASET_PATH = \"/content/plant_dataset\"   # where archive.zip was extracted\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 12           # start with 12 epochs; increase if you have time\n",
    "LEARNING_RATE = 1e-4\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/plant_training_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Dataset path:\", DATASET_PATH)\n",
    "print(\"Output dir:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.12,\n",
    "    height_shift_range=0.12,\n",
    "    shear_range=0.12,\n",
    "    zoom_range=0.12,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.20\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print('Found classes:', num_classes)\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "# Save mapping for frontend\n",
    "with open(os.path.join(OUTPUT_DIR, 'class_indices.json'), 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f, indent=2)\n",
    "print('Saved class_indices.json to', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "# Freeze most layers for fast training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "preds = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b173266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "checkpoint_path = os.path.join(OUTPUT_DIR, f'best_model_{timestamp}.keras')\n",
    "csv_log_path = os.path.join(OUTPUT_DIR, f'training_log_{timestamp}.csv')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "    CSVLogger(csv_log_path)\n",
    "]\n",
    "\n",
    "print('Checkpoint will be saved to:', checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional fine-tune: unfreeze last N layers of base_model\n",
    "N_UNFREEZE = 30\n",
    "for layer in base_model.layers[-N_UNFREEZE:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with lower LR\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE/10), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ft_checkpoint = os.path.join(OUTPUT_DIR, f'best_model_finetune_{timestamp}.keras')\n",
    "ft_csv = os.path.join(OUTPUT_DIR, f'finetune_log_{timestamp}.csv')\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint as MCP\n",
    "ft_callbacks = [\n",
    "    MCP(ft_checkpoint, monitor='val_accuracy', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-8, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "    CSVLogger(ft_csv)\n",
    "]\n",
    "\n",
    "print('Starting fine-tuning, unfreezing last', N_UNFREEZE, 'layers.')\n",
    "history_ft = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    callbacks=ft_callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39190228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (finetune if exists else head)\n",
    "best_model_path = ft_checkpoint if os.path.exists(ft_checkpoint) else checkpoint_path\n",
    "print('Loading best model from:', best_model_path)\n",
    "model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "loss, acc = model.evaluate(val_generator, verbose=1)\n",
    "print(f'Final validation accuracy: {acc:.4f}, loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5587544",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = os.path.join(OUTPUT_DIR, 'plant_disease_model.keras')\n",
    "print('Saving final model to:', final_model_path)\n",
    "model.save(final_model_path)\n",
    "print('Saved model. You can download it from Drive at:', final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f80671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally download to local machine (may be large)\n",
    "from google.colab import files\n",
    "files.download(final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15532694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_hist(h):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(h.history.get('accuracy', []), label='train_acc')\n",
    "    plt.plot(h.history.get('val_accuracy', []), label='val_acc')\n",
    "    plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h.history.get('loss', []), label='train_loss')\n",
    "    plt.plot(h.history.get('val_loss', []), label='val_loss')\n",
    "    plt.legend(); plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Plot head and finetune if available\n",
    "if 'history' in globals():\n",
    "    plot_hist(history)\n",
    "if 'history_ft' in globals():\n",
    "    plot_hist(history_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed108cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test prediction helper\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'class_indices.json')) as f:\n",
    "    class_idx = json.load(f)\n",
    "idx_to_class = {int(v):k for k,v in enumerate(class_idx.keys())}  # placeholder\n",
    "\n",
    "def predict_image(img_path, model_path=final_model_path):\n",
    "    img = Image.open(img_path).convert('RGB').resize(IMG_SIZE)\n",
    "    arr = np.array(img)/255.0\n",
    "    arr = np.expand_dims(arr, 0)\n",
    "    m = tf.keras.models.load_model(model_path)\n",
    "    preds = m.predict(arr)\n",
    "    idx = int(np.argmax(preds))\n",
    "    # build proper reverse mapping from saved JSON\n",
    "    rev_map = {v:k for k,v in class_idx.items()}\n",
    "    return rev_map[str(idx)], float(np.max(preds))\n",
    "\n",
    "# Example usage:\n",
    "# print(predict_image('/content/plant_dataset/Apple___Black_rot/0a...jpg'))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
